<html><head><meta name="robots" content="index,follow">
<title>HMM & HMM_ObservationSequence: Get cross-entropy</title></head><body bgcolor="#FFFFFF">

<table border=0 cellpadding=0 cellspacing=0><tr><td bgcolor="#CCCC00"><table border=4 cellpadding=9><tr><td align=middle bgcolor="#000000"><font face="Palatino,Times" size=6 color="#999900"><b>
HMM & HMM_ObservationSequence: Get cross-entropy
</b></font></table></table>
<p>
Calculates the cross-entropy between the selected <a href="HMM.html">HMM</a> model and the <a href="HMM_ObservationSequence.html">HMM_ObservationSequence</a>.</p>
<p>
The cross-entropy is a useful upper bound for the entropy of a model. An approximation to the cross-entropy for a model on a observation sequence  <i>O</i> of length <i>N</i> is: </p>
<table width="100%"><tr><td align=middle>
<i>H</i>(<i>O</i>) = -1/<i>N</i> log <i>p</i>(<i>O</i>),</table>
<p>
where <i>p</i>(<i>O</i>) is the probability of the observation sequence given the model.</p>
<hr>
<address>
	<p>&copy; djmw, October 17, 2010</p>
</address>
</body>
</html>
